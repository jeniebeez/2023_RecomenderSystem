{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087d6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import AlgoBase, Dataset, PredictionImpossible\n",
    "from surprise import BaselineOnly, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "\n",
    "# path to dataset file\n",
    "file_path = os.path.expanduser(\"C:/Users/AI-Lab/Desktop/推薦系統/ml-100k/ml-100k/u.data\")\n",
    "\n",
    "# As we're loading a custom dataset, we need to define a reader. In the\n",
    "# movielens-100k dataset, each line has the following format:\n",
    "# 'user item rating timestamp', separated by '\\t' characters.\n",
    "reader = Reader(line_format=\"user item rating timestamp\", sep=\"\\t\")\n",
    "\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d6695e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy sparse cosine similarity matrix\n",
    "num_items = 1682  # Update this to the actual number of items in your dataset\n",
    "density = 0.01  # The density of the matrix\n",
    "data_points = np.random.choice([0, 1], size=(num_items, num_items), p=[1 - density, density])\n",
    "cosine_sim_sparse = csr_matrix(data_points)\n",
    "cosine_sim_sparse.setdiag(np.ones(num_items))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ebc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom algorithm using the cosine similarity\n",
    "class CosineSimilarityBasedAlgorithm(AlgoBase):\n",
    "    def __init__(self, cosine_sim, k=10):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.cosine_sim = cosine_sim\n",
    "        self.k = k  # Number of top similar items to consider\n",
    "        self.similarity_cache = {}  # Cache for storing item similarities\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        return self\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible('User and/or item is unknown.')\n",
    "\n",
    "        if i not in self.similarity_cache:\n",
    "            # Compute top-k similar items\n",
    "            similarities = self.cosine_sim[i].toarray().ravel()\n",
    "            top_k_items = np.argsort(similarities)[-self.k:][::-1]\n",
    "            self.similarity_cache[i] = top_k_items\n",
    "\n",
    "        neighbors = [(alt_iid, self.cosine_sim[i, alt_iid])\n",
    "                     for alt_iid in self.similarity_cache[i]\n",
    "                     if self.trainset.knows_item(alt_iid) and alt_iid != i]\n",
    "\n",
    "        if not neighbors:\n",
    "            raise PredictionImpossible('No neighbors')\n",
    "\n",
    "        sim_total = weighted_sum = 0\n",
    "        for alt_iid, similarity in neighbors:\n",
    "          for (item, rating) in self.trainset.ur[u]:\n",
    "            if item == alt_iid:\n",
    "              similarity_value = similarity  # similarity is already an integer\n",
    "              sim_total += similarity_value\n",
    "              weighted_sum += similarity_value * rating\n",
    "              break\n",
    "          if sim_total == 0:\n",
    "            raise PredictionImpossible('No neighbors with non-zero similarity')\n",
    "\n",
    "        predicted_rating = weighted_sum / sim_total if sim_total else 0\n",
    "        return predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52426394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm CosineSimilarityBasedAlgorithm on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.1439  1.1422  1.1408  1.1423  0.0013  \n",
      "Fit time          0.00    0.01    0.01    0.01    0.00    \n",
      "Test time         6.67    6.46    6.45    6.53    0.10    \n"
     ]
    }
   ],
   "source": [
    "# Instantiate the custom algorithm with the precomputed cosine similarity matrix\n",
    "algo = CosineSimilarityBasedAlgorithm(cosine_sim=cosine_sim_sparse, k=10)\n",
    "\n",
    "# Evaluate the performance on the dataset\n",
    "results = cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de359d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "from surprise.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Train the algorithm on the training set\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Make recommendations for all users in the test set\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c93cb208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize predictions into a dictionary where keys are user IDs and values are lists of recommended item IDs\n",
    "user_predictions = {}\n",
    "for prediction in predictions:\n",
    "    user_id = prediction.uid\n",
    "    item_id = prediction.iid\n",
    "    estimated_rating = prediction.est\n",
    "    if user_id not in user_predictions:\n",
    "        user_predictions[user_id] = []\n",
    "    user_predictions[user_id].append((item_id, estimated_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0d99335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG: 0.8211228297594961\n"
     ]
    }
   ],
   "source": [
    "# Calculate NDCG for each user\n",
    "user_true_ratings = {}\n",
    "for uid, iid, true_r in testset:\n",
    "    if uid not in user_true_ratings:\n",
    "        user_true_ratings[uid] = {}\n",
    "    user_true_ratings[uid][iid] = true_r\n",
    "\n",
    "# calcuate every client NDCG\n",
    "ndcg_scores = []\n",
    "for uid, user_ratings in user_predictions.items():\n",
    "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    true_ratings = [user_true_ratings[uid][iid] if iid in user_true_ratings[uid] else 0 for iid, _ in user_ratings[:10]]\n",
    "    estimated_ratings = [rating for _, rating in user_ratings[:10]]\n",
    "    dcg = sum([(2 ** true - 1) / np.log2(i + 2) for i, true in enumerate(true_ratings)])\n",
    "    idcg = sum([(2 ** true - 1) / np.log2(i + 2) for i, true in enumerate(sorted(true_ratings, reverse=True))])\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0\n",
    "    ndcg_scores.append(ndcg)\n",
    "\n",
    "average_ndcg = np.mean(ndcg_scores)\n",
    "print(\"Average NDCG:\", average_ndcg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
